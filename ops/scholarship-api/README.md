# Scholarship API - Operations Artifacts

This directory contains operational artifacts generated by monitoring and validation scripts.

## Artifact Files

### `daily_ops_snapshot.json`
**Generated by:** `scripts/daily_ops.py`  
**Frequency:** Daily (recommended: 3x per day)  
**Contains:**
- Health summary (status, error rate, P95 compliance)
- Latency snapshot (overall + by endpoint group)
- Slow endpoints flagged (P95 >200ms)
- 24-hour KPI metrics
- Success criteria validation

**Example:**
```bash
python scripts/daily_ops.py
cat ops/scholarship-api/daily_ops_snapshot.json | jq
```

---

### `optimization_before_after.md`
**Generated by:** `scripts/release_validation.py`  
**Frequency:** Before major releases / optimization sprints  
**Contains:**
- Before/after performance comparison
- P95 reduction (goal: -80 to -120ms)
- Optimization steps executed
- Endpoint group performance changes
- Stress test validation results
- Recommendations for next steps

**Example:**
```bash
python scripts/release_validation.py
cat ops/scholarship-api/optimization_before_after.md
```

---

### `kpi_24h.txt`
**Generated by:** `scripts/kpi_reporting.py`  
**Frequency:** Daily (end of day)  
**Contains:**
- Feature usage (quick-wins, stretch-opportunities, predictive matching, document bulk analyze)
- Conversion funnel (endpoint usage → application starts)
- Credit economy (consumption by feature)
- Revenue impact (24h revenue → MRR estimates)
- Business metrics summary (active users, revenue per user)
- Insights and recommendations

**Example:**
```bash
python scripts/kpi_reporting.py
cat ops/scholarship-api/kpi_24h.txt
```

---

### `stress_test_results.md`
**Generated by:** `scripts/incident_response.py`  
**Frequency:** Pre-release, incident response  
**Contains:**
- Hot-path stress test results (4 critical endpoints)
- Latency distribution (P50/P90/P95/P99)
- Error rate analysis
- Auth regression checks
- Issues identified (with severity and fixes)
- Rollback decision (based on error rate >5% OR auth failures >0.5%)
- Detailed test output

**Example:**
```bash
python scripts/incident_response.py
cat ops/scholarship-api/stress_test_results.md
```

---

## Directory Structure

```
ops/scholarship-api/
├── README.md                      # This file
├── daily_ops_snapshot.json        # Daily operations baseline
├── optimization_before_after.md   # Release validation report
├── kpi_24h.txt                    # KPI and revenue report
└── stress_test_results.md         # Incident response report
```

---

## Usage Patterns

### Morning Routine
```bash
python scripts/daily_ops.py
# Check: ops/scholarship-api/daily_ops_snapshot.json
```

### Pre-Release Checklist
```bash
python scripts/release_validation.py
python scripts/incident_response.py
# Check: ops/scholarship-api/optimization_before_after.md
# Check: ops/scholarship-api/stress_test_results.md
```

### End of Day
```bash
python scripts/kpi_reporting.py
# Check: ops/scholarship-api/kpi_24h.txt
```

### Incident Response
```bash
python scripts/incident_response.py
# Exit code 1 = rollback required
# Exit code 0 = system healthy
```

---

## Integration with CI/CD

Add to your deployment pipeline:

```yaml
# Daily ops check
- run: python scripts/daily_ops.py
- run: cat ops/scholarship-api/daily_ops_snapshot.json

# Pre-deploy validation
- run: |
    python scripts/incident_response.py
    if [ $? -eq 1 ]; then
      echo "Rollback trigger - deployment blocked"
      exit 1
    fi

# Post-deploy KPI
- run: python scripts/kpi_reporting.py
- run: cat ops/scholarship-api/kpi_24h.txt
```

---

## Alert Thresholds

| Metric | Warning | Critical | Action |
|--------|---------|----------|--------|
| Error Rate | >0.5% | >5% | Rollback |
| Auth Failures | >0.1% | >0.5% | Rollback |
| P95 Latency | >120ms | >300ms | Optimize |
| Slow Queries | >0 | >5 | Investigate |

---

## Documentation

- **Full Runbook:** `../OPERATIONS_RUNBOOK.md`
- **Quick Start:** `../DAILY_OPS_QUICKSTART.md`
- **Prompts Reference:** `../OPS_PROMPTS_REFERENCE.md`

---

**Last Updated:** 2025-10-27  
**Version:** 1.0.0
